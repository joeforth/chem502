{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop - Exploratory Data Analysis\n",
    "\n",
    "In this workshop, we will work with a dataset of thermochemical data for some molecules to explore what features or descriptors are influential in their melting and/or boiling points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful resources\n",
    "\n",
    "We will be using some of the python libraries you have already seen and Seaborn, which you might not have yet. Here are some quick start guides and/or tutorials that might come in useful.\n",
    "\n",
    "- Pandas\n",
    "  - [10 minutes to pandas](https://pandas.pydata.org/docs/user_guide/10min.html)\n",
    "- Matplotlib\n",
    "  - [Quick start guide](https://matplotlib.org/stable/users/explain/quick_start.html)\n",
    "- RDKit\n",
    "  - [Getting started with the RDKit in Python](https://www.rdkit.org/docs/GettingStartedInPython.html)\n",
    "  - [RDKit tutorial from 2021](https://github.com/greglandrum/AIDD_RDKit_Tutorial_2021/blob/b4c4661ff7980721823654f54cd0c28031c5884c/RDKit_Intro.ipynb) - this covers a lot of ground. We won't be talking about reactions (towards end of notebook)\n",
    "  - There are also lots of videos on YouTube and of course ChatGPT (though I am not sure how well it does with RDKit, probably because the documentation is patchy).\n",
    "\n",
    "\n",
    "You might also find some useful bits and pieces in the [Molecular fingerprints notebook](https://drsamchong.github.io/c3d-book/1-chem_data/fingerprints.html) in the module book.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing the Libraries\n",
    "\n",
    "Let's start by importing some libraries:\n",
    "\n",
    "- time (needed to include a sleep)\n",
    "- requests\n",
    "- pandas \n",
    "- numpy\n",
    "- matplotlib\n",
    "- seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your import statements here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the Data\n",
    "\n",
    "The data is stored in a flat csv file in the `data` directory called `alcohol_acid_phys_data.csv`.\n",
    "\n",
    "0. Check the data in the file (try the 'head' command)\n",
    "1. Read the data into a pandas dataframe\n",
    "2. Display the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "# 1. Read the data into a pandas dataframe\n",
    "# 2. Display the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning the data\n",
    "\n",
    "We need to do at least a little cleaning of the data. We can check the data for the number of rows and the data types in each column using [`DataFrame.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "\n",
    "# 1. Run DataFrame.info() for *your* dataframe to get an overview of the contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Handling Missing Values\n",
    "There are lots of pKa values missing. We are not going to use the pKa values, so we can drop those columns.\n",
    "\n",
    "Some rows are missing densities. And more importantly, some are missing melting and/or boiling points, which is the property we are interested in.\n",
    "\n",
    "For a full run-through of handling missing data in pandas, read the [full documentation](https://pandas.pydata.org/docs/user_guide/missing_data.html#missing-data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "# 1. Drop the two pKa columns\n",
    "# 2. Drop the rows with NaN values in density, melting point and boiling point columns.\n",
    "# 3. Check the info again to see if the changes have been made.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Handling Weird Strings\n",
    "\n",
    "Still a few issues:\n",
    "\n",
    "- The `Class` and `IUPAC name` columns have some odd characters which appear to encode whitespace, e.g. the `\\r` and `\\n` in Alkanedioic\\r\\nacid.\n",
    "\n",
    "- Running `DataFrame.info()` shows that the melting and boiling points have object (i.e. string) data types, which suggests there are non-numerical values. If you look at the columns, some numbers have \"d\" or \"s\" sometimes with a number, probably to denote \"decomposed\" or \"sublimed\" maybe.\n",
    "\n",
    "Pandas has `str.contains`, `replace` and `str.replace` functions. Try using these to check and remove the encoded characters in those columns.\n",
    "\n",
    "Can you think of a way to deal with the non- or partly numeric phase change values?\n",
    "\n",
    "**Hints**\n",
    "\n",
    "For (1.) could [this](https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html) help?\n",
    "\n",
    "For (2.) note that `str.replace()` and `replace()` work differently - you'll have to explore a little to get them to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "# 1. Ensure only numeric values are present in the melting point, boiling point columns\n",
    "# 2. Remove the encoded whitespace characters from the 'Class' and 'IUPAC name' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the compounds do not have common names. We could either drop the column or fill the missing values with something like \"unknown\" or \"none\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "\n",
    "# 3. Clean column with missing compounds' common names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `DataFrame.info()` one last time for your dataframe - Does every column have the same number of non-null values? If not, read on...\n",
    "\n",
    "If you converted the mp and bp columns to numeric types using `pd.to_numeric` with `errors=\"coerce\"` then you will probably now have some additional null values in those columns, so those rows can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (If necessary): \n",
    "\n",
    "# 4. Drop any remaining rows with NaN values in mp/bp columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have a clean dataset with no missing values and the correct dtypes.\n",
    "\n",
    "We can look at the summary statistics for the numerical columns we currently have, but there's not much there yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cleaning Categorical Data\n",
    "\n",
    "There is one more thing we can do to tidy this data. Most of the data in this dataset can take an infinite number of values (e.g., boiling point). By contrast, others could potentially only have a finite number of values - we call this 'categorical' data.\n",
    "\n",
    "`pandas` has a special dtype for categorical data - `category`. There are huge performance benefits to using it with large datasets. Consider the columns in your datset - which do you think you could get away with storing as categorical data? \n",
    "\n",
    "Convert the appropriate column(s) to categorical data. You'll find the `unique()` and `astype()` functions are useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# \n",
    "# 1. Check for categorical columns and change the data type to 'category' if necessary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualising the Data\n",
    "\n",
    "Have a look at this brilliant [seaborn tutorial](https://weisscharlesj.github.io/SciCompforChemists/notebooks/chapter_10/chap_10_notebook.html) developed by Charles J. Weiss at Augustana University in South Dakota.\n",
    "\n",
    "Some of the data used has a similar structure to this dataset.\n",
    "\n",
    "There are no hard and fast rules about which types of plots to use to visualise your data, but the data types of the columns will mean some are more suitable to look at the data and relationships for certain variables.\n",
    "\n",
    "Visualise your data in a way that allows you to explore the following:\n",
    "\n",
    "1. The distribution of different classes of compound in the data set\n",
    "2. Identify if there are any outliers for the thermochemical data or density\n",
    "3. The distribution of boiling points, melting point and/or density with the class of the compound\n",
    "4. Identify any correlations between the numerical features and the melting and/or boiling point.\n",
    "5. Is there any difference for different classes of compound?\n",
    "\n",
    "Are there any other interesting patterns or trends in the data that you have observed?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Summary\n",
    "\n",
    "- You have used the pandas library to clean and prepare a dataset, and to get descriptive statistics for the data.\n",
    "\n",
    "- You have used the seaborn library to visualise distributions and relationships in the data to look for anomalies and patterns.\n",
    "\n",
    "Next week, we'll build on this dataset to start exploring Cheminformatics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
